 Short list of features I plan to add to SPTF

 * Support for Win32
 * Support for class + method execution style in other languages (Ruby, Python, etc).
 * Replace metadata format (YAML) with other format. Probably using Config:Std (?).
 * Split more code into subroutines. One day SPTF will became a class maybe.
 * Split current help into short help and more verbose man.
 * Method parameters within metadata should be any data structure and not only array (damn!).
 * *Plugin capability*. Load dynamically module to do something with the executed test<br>entity (case,scenario,test result) or maybe some other stuff as well. I don't know yet, but it sounds cool.
 * Database to archive test results. (I'm not sure about this now).
 * 'quiet' option for the test session. No test results goes to the output. Only return code.
 * Configurable timeout for each test case.
 * Count time for each test case
{{{
 # ./sptf --run --scenario-id 10 --total-tc-time
 ok - [1] my great test 
 # Total time TC[1]: 0:12:34.402
 ok - [2] my other test
 # Total time TC[2]: 0:00:01.321
}}}
 * *Failure reaction*. Configurable option to execute additional operation when test case failed. (_onfailure_ tag)
 * *Coverage*. New tag in metadata - feature. I assume that running all tests with given feature will<br>give 100% coverage for this feature. Disputable, but currently I like the idea.
{{{
 # ./sptf --run --scenario-id 10 --coverage
   ........
   TAP test results
   ........
# +---------+----------+-------------+--------------+
# | Feature | Total TC | Executed TC | Coverage (%) |
# +---------+----------+-------------+--------------+
# |   DB    |   130    |    103      |      79      |
# +---------+----------+-------------+--------------+
# |  GUI    |   200    |    200      |     100      |
# +---------+----------+-------------+--------------+
# |  CLI    |    50    |      1      |     0.2      |
# +---------+----------+-------------+--------------+
}}}
 Maybe successful statistics should be part of the coverage.<br>For less optimistic between us.(?)
{{{
# +---------+----------+-------------+------------|--------------+
# | Feature | Total TC | Executed TC | Passed TC  | Coverage (%) |
# +---------+----------+-------------+------------|--------------+
# |   DB    |   130    |    103      |    100     |      77      |
# +---------+----------+-------------+---------------------------+
# |  GUI    |   200    |    200      |     20     |      10      |
# +---------+----------+-------------+---------------------------+
# |  CLI    |    50    |      1      |      0     |       0      |
# +---------+----------+-------------+---------------------------+
}}}
 The table output should be TAP compatible.
 * *Showstopper*. Showstopper is test case ID where upon its failure, the whole test scenario will stop.
 * *Dependency on failure*. Lets say, test case 2 depend on failure of test case 1. If test case 1 fail, test case 2 won't be executed and will report failure.
 * Executing test cases/scenarios by given tag(s). 
 * Logical operations on tags (thanks, Blumzi). 
 {{{
 # ./sptf --run --test-tag (sanity and not regression) and (server or client)
 }}}
 or
{{{
 # ./sptf --show-summary --test-tag (customer or acceptance)
}}}
 * Executing test cases by given author.
 * Allow certain number of failures in test scenario. Will overwrite the continuity option in test case.
 * Multiple ID test case dependency.
 * Show in which scenarios appears given test case.
{{{
 # ./sptf --show-scenario --test-id 102
 TC[102] appears in scenarios: 1,15,23
}}}
 * Execute given program before running the test, quit the test if pre program failed (sic?)
{{{
 # ./sptf --run --pre-test pre/create-env.pl --scenario-id 1
}}}
 * Execute given program after the test. (_--post-test_)
 * Cancel pre/post requisite operations in test case. This way you may run the same test case once within scenario<br>where test cases depend each on another, but also in the random manner<br>where pre/post operation would build and destroy specific test case environment (fixture testing).
{{{
 # ./sptf --run --test-id 1,2,3,4 --no-prereq --no-postreq
}}}
 or
{{{
 # ./sptf --run --scenario-id 1 --no-prereq --no-postreq
}}} 
 * Cancel test cases dependency
{{{
 # ./sptf --run --scenario-id 1 --no-tc-dependency
}}}
 * Execute specific test cases in random mode. (shuffle)
{{{
 # ./sptf --run --all-tests --shuffle --test-id 1,2,3,4
}}}
 * Execute random number (in the range) of test cases from the entire pull of test cases in random way
{{{
 # ./sptf --run --all-tests --shuffle --min 10 --max 200
}}}
 * Execute exact number of test cases for the entire test cases pull in random way.
{{{
 # ./sptf --run --all-tests --shuffle --min 256 --max 256
}}}
 * The same way for the entire scenarios pull as well
{{{
 # ./sptf --run --shuffle --min 5 --max 10 --all-scenarios
}}}
 * Execute random test cases based on shuffle family (tag in metadata). For example
 {{{
 # ./sptf --run --shuffle-family 1,4,3 --min 10 --max 20 --all-tests
 }}}
 will pick random test case from shuffle family 1 and execute, then random test case from shuffle family 2 and execute and so on 10 times.<br>It's good when test cases in only certain group of tests may be execute independently one from another. (I'm not sure about this) 
 * Maybe even to run specific number of test cases/scenarios for each shuffle family
{{{
 # ./sptf --run --shuffle-family 1:10,4:2,3:1024 --all-tests
}}}
 will pick random 10 test cases from shuffle family 1 and execute them, then 2 test cases for shuffle family 4 and so on. 
 * Current meta-scenario syntax is not build for the *shuffle* stuff. Fix it.
 * Any environmental variable maybe import into the test environment. May be helpful for example<br>with layered TAP diagnostics in Test Builder mode or for setting up logging layers.
{{{
 # ./sptf --run --test-id 1,2,3,4 --env-var DO_TRACE --env-var DEBUG_LEVEL=4
}}}
 * Test scenario will support continuity option.
 * Show all test cases/scenarios belongs to given author.
{{{
 # ./sptf --show-tests --author me
# +--------+-------------------------------+
# | Author | Test ID                       |
# +--------+-------------------------------+
# | me     | 1,2,3,4,5,19,20,44,100,230,23 |
# +--------+-------------------------------+
}}}
 * Check if the method belongs to the class before it's execute. Report TAP on failure.
 * *Test duration*. Each test case will have the metadata tag - _duration_. If so, *SPTF* will be able to supply several services.<br>
{{{
 # ./sptf --show-duration --scenario-id 1
 This scenario will durate: 0:31:44.302
}}}
 or
{{{
 # ./sptf --run --shuffle --all-tests --no-longer-then 30min
}}}
 will execute random number of test cases with total runtime less then 30min. 
 * Show all bugs and the TC ids they belongs to
{{{
 # ./sptf --show-all-bugs
# +-------+---------+
# | Bug   | Test ID |
# +-------+---------+
# | 00123 |   1     |
# +-------+---------+
# | 00442 |  107    |
# +-------+---------+
}}}
 * Don't execute given TC
{{{
 # ./sptf --run --scenario 1 --dont-run 20,23,38
}}}
 will execute test scenario 1 but without test cases 20,23,38

Some ideas here may oppose one to another. Maybe each one will have its importancy level, to avoid conflicts.